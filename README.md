# Telegram-бот с локальной LLM (LM Studio) и поддержкой контекста

Этот репозиторий содержит Telegram-бота, который отвечает на сообщения пользователя,
используя **локальную языковую модель**, запущенную через **LM Studio**.  
Бот хранит **контекст диалога** для каждого пользователя и умеет очищать его по команде `/clear`.
Также вы можете узнать какая используется LLM с помощью команды `/model`

# Как этим пользоваться?
1) Создайте Telegram бота с помощью BotFather и получите Api token для него
2) Скачайте LM Studio и интересующую вас модель (я использовал Qwen2.5-1.5B-Instruct-Q6_K.gguf, если у вас мощное устройство можете скачать Qwen2.5-1.5B-Instruct-Q8_K.gguf)
3) В разделе Developer LM Studio поставьте флаг Status: Stopped
4) Склонируйте себе этот репозиторий и добавьте файл .env в котором укажите Api token своего бота в формате (API_TOKEN = <свой Api token>)
5) Запустите программу и пользуйтесь локально
